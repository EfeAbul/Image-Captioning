# Image Captioning Project

This project focuses on generating descriptive captions for images using deep learning. A visual encoder is used to extract features from input images, and a language model generates natural language descriptions based on these features.

## Contents

- `Image_Captioning.ipynb`: Main notebook containing the entire workflow including data loading, model training, and caption generation.
- `data/`: Contains supporting files such as sample annotations or small test inputs.
- `outputs/`: Stores generated captions and results.

## Dataset

The full dataset used in this project (including images and annotations) is hosted externally due to size limitations.  
You can download it from the link below:

[Download the dataset](https://drive.google.com/drive/folders/12MrQf0s39WKGB-81ftvZ6x6KgucODXGU?usp=drive_link)

## Usage

1. Download the dataset and place it in the appropriate directory.
2. Run `Image_Captioning.ipynb` in Jupyter Notebook or Google Colab (You need to update the file paths accordingly).
3. Follow the notebook cells to train the model and generate captions from images.

## Author

Efe Abul  
